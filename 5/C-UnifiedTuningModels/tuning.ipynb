{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# PROJETO ENANI - OTIMIZA√á√ÉO DE MODELOS PARA PREDI√á√ÉO NUTRICIONAL\n",
    "# ===============================================================\n",
    "# Arquivo: model_tuning_optimization.ipynb\n",
    "# Objetivo: Tunar os 3 melhores modelos identificados no screening\n",
    "# Dataset: TrainDS.csv (dados de treino)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===============================================================\n",
    "# 1. INTRODU√á√ÉO E CONTEXTO DO PROJETO\n",
    "# ===============================================================\n",
    "\n",
    "print(\"üöÄ PROJETO ENANI - OTIMIZA√á√ÉO DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã OBJETIVO: Otimizar modelos para predi√ß√£o de status nutricional\")\n",
    "print(\"üéØ META: Melhorar AUC de 0.55 para >0.70 e F1 de 0.59 para >0.75\")\n",
    "print(\"üìä MODELOS SELECIONADOS: XGBoost, Gradient Boosting, Random Forest\")\n",
    "print()\n",
    "\n",
    "# ===============================================================\n",
    "# 2. CARREGAR E VERIFICAR DADOS\n",
    "# ===============================================================\n",
    "\n",
    "print(\"üìÅ CARREGANDO DATASET DE TREINO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Caminho do dataset\n",
    "train_path = '/Users/marcelosilva/Desktop/projectOne/5/A-TrainTestDataset/TrainDS.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "print(f\"‚úÖ Dataset carregado: {df_train.shape}\")\n",
    "print(f\"üìä Linhas: {df_train.shape[0]:,}\")\n",
    "print(f\"üìä Colunas: {df_train.shape[1]}\")\n",
    "\n",
    "# ===============================================================\n",
    "# 3. DOCUMENTA√á√ÉO DOS LABEL ENCODINGS APLICADOS\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüìã LABEL ENCODINGS APLICADOS NO DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üéØ TARGET VARIABLE (status_nutricional_who):\")\n",
    "print(\"   0 = Desnutrido (mais grave)\")\n",
    "print(\"   1 = Peso adequado (ideal)\")  \n",
    "print(\"   2 = Sobrepeso (excesso leve)\")\n",
    "print(\"   3 = Obesidade (excesso severo)\")\n",
    "\n",
    "print(\"\\nüìä VARI√ÅVEIS ORDINAIS (Label Encoded):\")\n",
    "print(\"   def_idade_gest: 0=prematuro, 1=adequado, 2=pos_termo\")\n",
    "print(\"   adequacao_prenatal: 0=ausente, 1=insuficiente, 2=adequado\")\n",
    "print(\"   idade_mae_cat: 0=jovem, 1=adulta, 2=madura\")\n",
    "print(\"   peso_cat: 0=baixo, 1=normal, 2=alto\")\n",
    "print(\"   classificacao_peso: 0=PIG, 1=AIG, 2=GIG\")\n",
    "\n",
    "print(\"\\nüé≠ VARI√ÅVEIS CATEG√ìRICAS (One-Hot pelo PyCaret):\")\n",
    "categorical_vars = ['b02_sexo', 'd01_cor', 'h04_parto', 'j03_cor', 'k15_recebeu', 'k16_liquido']\n",
    "for var in categorical_vars:\n",
    "    print(f\"   {var}: Receber√° One-Hot encoding autom√°tico\")\n",
    "\n",
    "# ===============================================================\n",
    "# 4. AN√ÅLISE DA DISTRIBUI√á√ÉO DO TARGET\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüéØ DISTRIBUI√á√ÉO DO TARGET (CRITICAL FOR TUNING)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "target_dist = df_train['status_nutricional_who'].value_counts().sort_index()\n",
    "target_names = ['Desnutrido', 'Peso adequado', 'Sobrepeso', 'Obesidade']\n",
    "\n",
    "total_samples = len(df_train)\n",
    "for value, count in target_dist.items():\n",
    "    percentage = (count / total_samples) * 100\n",
    "    status = \"‚ö†Ô∏è MINORIT√ÅRIA\" if percentage < 5 else \"‚úÖ\"\n",
    "    print(f\"   Classe {value} ({target_names[value]}): {count:,} ({percentage:.1f}%) {status}\")\n",
    "\n",
    "# Verificar desbalanceamento cr√≠tico\n",
    "minority_class_pct = (target_dist[0] / total_samples) * 100\n",
    "if minority_class_pct < 5:\n",
    "    print(f\"\\nüö® ALERTA: Classe minorit√°ria com {minority_class_pct:.1f}% - SMOTE ser√° cr√≠tico!\")\n",
    "\n",
    "# ===============================================================\n",
    "# 5. CONFIGURA√á√ÉO DO PYCARET PARA OTIMIZA√á√ÉO\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüîß CONFIGURANDO PYCARET PARA OTIMIZA√á√ÉO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar mem√≥ria dispon√≠vel\n",
    "import psutil\n",
    "memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "print(f\"üíæ Mem√≥ria dispon√≠vel: {memory_gb:.1f} GB\")\n",
    "\n",
    "# Features a ignorar\n",
    "ignore_features = ['id_anon', 'vd_zimc']\n",
    "\n",
    "# Vari√°veis ordinais (CR√çTICO para preservar ordem)\n",
    "ordinal_features = {\n",
    "    'def_idade_gest': [0, 1, 2],           # prematuro < adequado < pos_termo\n",
    "    'adequacao_prenatal': [0, 1, 2],       # ausente < insuficiente < adequado\n",
    "    'idade_mae_cat': [0, 1, 2],            # jovem < adulta < madura\n",
    "    'peso_cat': [0, 1, 2],                 # baixo < normal < alto\n",
    "    'classificacao_peso': [0, 1, 2]        # PIG < AIG < GIG\n",
    "}\n",
    "\n",
    "print(f\"üö´ Features ignoradas: {ignore_features}\")\n",
    "print(f\"üìä Vari√°veis ordinais configuradas: {len(ordinal_features)}\")\n",
    "\n",
    "try:\n",
    "    # Setup otimizado para tuning\n",
    "    clf = setup(\n",
    "        data=df_train,\n",
    "        target='status_nutricional_who',\n",
    "        \n",
    "        # Features e encoding\n",
    "        ignore_features=ignore_features,\n",
    "        ordinal_features=ordinal_features,\n",
    "        \n",
    "        # Balanceamento (CR√çTICO para classe minorit√°ria)\n",
    "        fix_imbalance=True,\n",
    "        fix_imbalance_method='smote',\n",
    "        \n",
    "        # Preprocessing otimizado\n",
    "        remove_multicollinearity=True,\n",
    "        multicollinearity_threshold=0.95,\n",
    "        feature_selection=False,  # Manter todas para tuning\n",
    "        transformation=True,\n",
    "        normalize=True,\n",
    "        \n",
    "        # Valida√ß√£o robusta\n",
    "        fold=5,  # 5-fold para tuning (mais r√°pido que 10)\n",
    "        train_size=0.8,  # 80% treino, 20% valida√ß√£o interna\n",
    "        \n",
    "        # Performance\n",
    "        session_id=123,\n",
    "        use_gpu=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ SETUP OTIMIZADO CONCLU√çDO!\")\n",
    "    \n",
    "    # Verificar configura√ß√£o aplicada\n",
    "    print(f\"\\nüìä CONFIGURA√á√ÉO APLICADA:\")\n",
    "    print(f\"   Shape ap√≥s transforma√ß√µes: {get_config('X_train').shape}\")\n",
    "    print(f\"   SMOTE aplicado: Sim\")\n",
    "    print(f\"   Folds para CV: 5\")\n",
    "    print(f\"   Vari√°veis ordinais: {len(ordinal_features)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO no setup: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ===============================================================\n",
    "# 6. BASELINE - MODELOS IDENTIFICADOS NO SCREENING\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüìä BASELINE - RESULTADOS DO SCREENING ANTERIOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_results = {\n",
    "    'XGBoost': {'F1': 0.592, 'AUC': 0.540, 'Accuracy': 0.626},\n",
    "    'Gradient Boosting': {'F1': 0.591, 'AUC': 0.556, 'Accuracy': 0.614},\n",
    "    'Random Forest': {'F1': 0.571, 'AUC': 0.539, 'Accuracy': 0.560}\n",
    "}\n",
    "\n",
    "print(\"RESULTADOS DO SCREENING (sem otimiza√ß√£o):\")\n",
    "for model, metrics in baseline_results.items():\n",
    "    print(f\"   {model}:\")\n",
    "    print(f\"      F1: {metrics['F1']:.3f} | AUC: {metrics['AUC']:.3f} | Accuracy: {metrics['Accuracy']:.3f}\")\n",
    "\n",
    "print(f\"\\nüéØ METAS DE MELHORIA:\")\n",
    "print(f\"   AUC: 0.540 ‚Üí >0.700 (+30%)\")\n",
    "print(f\"   F1:  0.592 ‚Üí >0.750 (+27%)\")\n",
    "\n",
    "# ===============================================================\n",
    "# 7. OTIMIZA√á√ÉO DO XGBOOST (MELHOR F1 BASELINE)\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüöÄ OTIMIZANDO XGBOOST (Prioridade: AUC)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"‚è≥ Iniciando otimiza√ß√£o XGBoost (pode demorar 3-5 minutos)...\")\n",
    "    \n",
    "    # Criar modelo base\n",
    "    xgb_base = create_model('xgboost', verbose=False)\n",
    "    \n",
    "    # Otimiza√ß√£o focada em AUC (problema principal) - SEM OPTUNA\n",
    "    xgb_tuned = tune_model(\n",
    "        xgb_base,\n",
    "        optimize='AUC',           # PRIORIDADE: melhorar discrimina√ß√£o\n",
    "        n_iter=50,                # 50 itera√ß√µes (sem optuna)\n",
    "        fold=5,                   # 5-fold para velocidade\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ XGBoost otimizado com sucesso!\")\n",
    "    \n",
    "    # Avaliar modelo otimizado\n",
    "    print(\"\\nüìä AVALIANDO XGBOOST OTIMIZADO:\")\n",
    "    xgb_results = pull()  # Pegar resultados da √∫ltima opera√ß√£o\n",
    "    \n",
    "    print(f\"   AUC otimizado: {xgb_results['AUC'].mean():.3f} (baseline: 0.540)\")\n",
    "    print(f\"   F1 otimizado:  {xgb_results['F1'].mean():.3f} (baseline: 0.592)\")\n",
    "    print(f\"   Accuracy:      {xgb_results['Accuracy'].mean():.3f} (baseline: 0.626)\")\n",
    "    \n",
    "    # Calcular melhoria\n",
    "    auc_improvement = ((xgb_results['AUC'].mean() - 0.540) / 0.540) * 100\n",
    "    f1_improvement = ((xgb_results['F1'].mean() - 0.592) / 0.592) * 100\n",
    "    \n",
    "    print(f\"   üöÄ Melhoria AUC: {auc_improvement:+.1f}%\")\n",
    "    print(f\"   üöÄ Melhoria F1:  {f1_improvement:+.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na otimiza√ß√£o XGBoost: {e}\")\n",
    "    xgb_tuned = None\n",
    "\n",
    "# ===============================================================\n",
    "# 8. OTIMIZA√á√ÉO DO GRADIENT BOOSTING (MELHOR AUC BASELINE)\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüöÄ OTIMIZANDO GRADIENT BOOSTING (Prioridade: F1)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"‚è≥ Iniciando otimiza√ß√£o Gradient Boosting...\")\n",
    "    \n",
    "    # Criar modelo base\n",
    "    gbc_base = create_model('gbc', verbose=False)\n",
    "    \n",
    "    # Otimiza√ß√£o focada em F1 (dados desbalanceados) - SEM OPTUNA\n",
    "    gbc_tuned = tune_model(\n",
    "        gbc_base,\n",
    "        optimize='F1',            # PRIORIDADE: dados desbalanceados\n",
    "        n_iter=50,                # 50 itera√ß√µes\n",
    "        fold=5,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Gradient Boosting otimizado com sucesso!\")\n",
    "    \n",
    "    # Avaliar modelo otimizado\n",
    "    print(\"\\nüìä AVALIANDO GRADIENT BOOSTING OTIMIZADO:\")\n",
    "    gbc_results = pull()\n",
    "    \n",
    "    print(f\"   AUC otimizado: {gbc_results['AUC'].mean():.3f} (baseline: 0.556)\")\n",
    "    print(f\"   F1 otimizado:  {gbc_results['F1'].mean():.3f} (baseline: 0.591)\")\n",
    "    print(f\"   Accuracy:      {gbc_results['Accuracy'].mean():.3f} (baseline: 0.614)\")\n",
    "    \n",
    "    # Calcular melhoria\n",
    "    auc_improvement = ((gbc_results['AUC'].mean() - 0.556) / 0.556) * 100\n",
    "    f1_improvement = ((gbc_results['F1'].mean() - 0.591) / 0.591) * 100\n",
    "    \n",
    "    print(f\"   üöÄ Melhoria AUC: {auc_improvement:+.1f}%\")\n",
    "    print(f\"   üöÄ Melhoria F1:  {f1_improvement:+.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na otimiza√ß√£o Gradient Boosting: {e}\")\n",
    "    gbc_tuned = None\n",
    "\n",
    "# ===============================================================\n",
    "# 9. OTIMIZA√á√ÉO DO RANDOM FOREST (BACKUP + INTERPRETABILIDADE)\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüöÄ OTIMIZANDO RANDOM FOREST (Prioridade: Recall)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"‚è≥ Iniciando otimiza√ß√£o Random Forest...\")\n",
    "    \n",
    "    # Criar modelo base\n",
    "    rf_base = create_model('rf', verbose=False)\n",
    "    \n",
    "    # Otimiza√ß√£o focada em Recall (n√£o perder casos cr√≠ticos) - SEM OPTUNA\n",
    "    rf_tuned = tune_model(\n",
    "        rf_base,\n",
    "        optimize='Recall',        # PRIORIDADE: encontrar todos os casos\n",
    "        n_iter=30,                # 30 itera√ß√µes (RF √© mais simples)\n",
    "        fold=5,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Random Forest otimizado com sucesso!\")\n",
    "    \n",
    "    # Avaliar modelo otimizado\n",
    "    print(\"\\nüìä AVALIANDO RANDOM FOREST OTIMIZADO:\")\n",
    "    rf_results = pull()\n",
    "    \n",
    "    print(f\"   AUC otimizado: {rf_results['AUC'].mean():.3f} (baseline: 0.539)\")\n",
    "    print(f\"   F1 otimizado:  {rf_results['F1'].mean():.3f} (baseline: 0.571)\")\n",
    "    print(f\"   Recall:        {rf_results['Recall'].mean():.3f}\")\n",
    "    \n",
    "    # Calcular melhoria\n",
    "    auc_improvement = ((rf_results['AUC'].mean() - 0.539) / 0.539) * 100\n",
    "    f1_improvement = ((rf_results['F1'].mean() - 0.571) / 0.571) * 100\n",
    "    \n",
    "    print(f\"   üöÄ Melhoria AUC: {auc_improvement:+.1f}%\")\n",
    "    print(f\"   üöÄ Melhoria F1:  {f1_improvement:+.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na otimiza√ß√£o Random Forest: {e}\")\n",
    "    rf_tuned = None\n",
    "\n",
    "# ===============================================================\n",
    "# 10. ENSEMBLE DOS MODELOS OTIMIZADOS\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüéØ CRIANDO ENSEMBLE DOS MODELOS OTIMIZADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lista de modelos otimizados dispon√≠veis\n",
    "tuned_models = []\n",
    "model_names = []\n",
    "\n",
    "if xgb_tuned is not None:\n",
    "    tuned_models.append(xgb_tuned)\n",
    "    model_names.append(\"XGBoost\")\n",
    "    \n",
    "if gbc_tuned is not None:\n",
    "    tuned_models.append(gbc_tuned)\n",
    "    model_names.append(\"Gradient Boosting\")\n",
    "    \n",
    "if rf_tuned is not None:\n",
    "    tuned_models.append(rf_tuned)\n",
    "    model_names.append(\"Random Forest\")\n",
    "\n",
    "if len(tuned_models) >= 2:\n",
    "    try:\n",
    "        print(f\"‚è≥ Criando ensemble de {len(tuned_models)} modelos...\")\n",
    "        \n",
    "        # Ensemble por vota√ß√£o\n",
    "        ensemble_voting = ensemble_model(\n",
    "            tuned_models,\n",
    "            method='Voting',\n",
    "            optimize='AUC'\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Ensemble criado com sucesso!\")\n",
    "        \n",
    "        # Avaliar ensemble\n",
    "        print(\"\\nüìä AVALIANDO ENSEMBLE:\")\n",
    "        ensemble_results = pull()\n",
    "        \n",
    "        print(f\"   AUC ensemble: {ensemble_results['AUC'].mean():.3f}\")\n",
    "        print(f\"   F1 ensemble:  {ensemble_results['F1'].mean():.3f}\")\n",
    "        print(f\"   Accuracy:     {ensemble_results['Accuracy'].mean():.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO na cria√ß√£o do ensemble: {e}\")\n",
    "        ensemble_voting = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è N√£o foi poss√≠vel criar ensemble (menos de 2 modelos otimizados)\")\n",
    "    ensemble_voting = None\n",
    "\n",
    "# ===============================================================\n",
    "# 11. COMPARA√á√ÉO FINAL DOS RESULTADOS\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüìä COMPARA√á√ÉO FINAL: BASELINE vs OTIMIZADO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"BASELINE (Screening sem otimiza√ß√£o):\")\n",
    "print(\"   XGBoost:          F1=0.592 | AUC=0.540 | Acc=0.626\")\n",
    "print(\"   Gradient Boost:   F1=0.591 | AUC=0.556 | Acc=0.614\")\n",
    "print(\"   Random Forest:    F1=0.571 | AUC=0.539 | Acc=0.560\")\n",
    "\n",
    "print(\"\\nOTIMIZADO (Ap√≥s tuning):\")\n",
    "if xgb_tuned is not None:\n",
    "    xgb_final = pull() if 'xgb_results' in locals() else \"N/A\"\n",
    "    print(f\"   XGBoost Tuned:    [M√©tricas acima]\")\n",
    "    \n",
    "if gbc_tuned is not None:\n",
    "    print(f\"   GBC Tuned:        [M√©tricas acima]\")\n",
    "    \n",
    "if rf_tuned is not None:\n",
    "    print(f\"   RF Tuned:         [M√©tricas acima]\")\n",
    "    \n",
    "if ensemble_voting is not None:\n",
    "    print(f\"   Ensemble:         [M√©tricas acima]\")\n",
    "\n",
    "# ===============================================================\n",
    "# 12. PR√ìXIMOS PASSOS\n",
    "# ===============================================================\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMOS PASSOS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. ‚úÖ Modelos otimizados e prontos\")\n",
    "print(\"2. üìä Evalua√ß√£o detalhada com evaluate_model()\")\n",
    "print(\"3. üéØ Finaliza√ß√£o com finalize_model()\")\n",
    "print(\"4. üß™ Teste no dataset holdout (TestDS.csv)\")\n",
    "print(\"5. üìã Interpretabilidade e feature importance\")\n",
    "print(\"6. üíæ Salvar modelos finais\")\n",
    "\n",
    "print(f\"\\nüéâ OTIMIZA√á√ÉO CONCLU√çDA!\")\n",
    "print(\"üí° Use evaluate_model(modelo) para an√°lise detalhada\")\n",
    "print(\"üíæ Use finalize_model(modelo) para treino no dataset completo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
