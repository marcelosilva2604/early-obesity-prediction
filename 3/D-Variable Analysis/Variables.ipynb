{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee0d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/marcelosilva/Desktop/projectOne/3/C-Variable Analysis/complete_cases_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedb9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (4339, 24)\n",
      "\n",
      "Number of NaN values in each column:\n",
      "id_anon                   0\n",
      "b02_sexo                  0\n",
      "b04_idade                 0\n",
      "bb04_idade_da_mae         0\n",
      "d01_cor                   0\n",
      "h01_semanas_gravidez      0\n",
      "h02_peso                  0\n",
      "h03_altura                0\n",
      "h04_parto                 0\n",
      "j03_cor                   0\n",
      "k04_prenatal_semanas      0\n",
      "k05_prenatal_consultas    0\n",
      "k06_peso_engravidar       0\n",
      "k07_peso_final            0\n",
      "k08_quilos                0\n",
      "k12_tempo                 0\n",
      "k13_tempo_medida          0\n",
      "k15_recebeu               0\n",
      "k16_liquido               0\n",
      "k18_somente               0\n",
      "k19_somente_medida        0\n",
      "t05_altura_medida1        0\n",
      "t06_altura_medida2        0\n",
      "vd_zimc                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show shape of the dataframe\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# Check for NaN values in each column\n",
    "print(\"\\nNumber of NaN values in each column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60bcc27",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning: Handling Missing Responses in Categorical Variables\n",
    "\n",
    "In this step, we will remove the \"Don't know/No response\" categories from the categorical variables in our dataset. This cleaning process is essential to:\n",
    "\n",
    "- Improve data quality\n",
    "- Focus on valid responses\n",
    "- Reduce noise in our analysis\n",
    "- Prepare the data for meaningful statistical analysis\n",
    "\n",
    "The categorical variables that will be cleaned are:\n",
    "- b02_sexo (Sex)\n",
    "- d01_cor (Mother's skin color)\n",
    "- h04_parto (Type of delivery)\n",
    "- j03_cor (Child's skin color)\n",
    "- k13_tempo_medida (Time measure unit)\n",
    "- k15_recebeu (Received)\n",
    "- k16_liquido (Liquid)\n",
    "- k19_somente_medida (Only measure)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c658d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution for b02_sexo:\n",
      "           Count  Percentage\n",
      "b02_sexo                    \n",
      "Masculino   2207   50.864254\n",
      "Feminino    2132   49.135746\n",
      "\n",
      "Distribution for d01_cor:\n",
      "                                                    Count  Percentage\n",
      "d01_cor                                                              \n",
      "Parda (mulata, cabocla, cafuza, mameluca ou mes...   2267   52.247062\n",
      "Branca                                               1753   40.401014\n",
      "Preta                                                 292    6.729661\n",
      "Amarela (origem japonesa, chinesa, coreana etc.)       19    0.437889\n",
      "Ind√≠gena                                                8    0.184374\n",
      "\n",
      "Distribution for h04_parto:\n",
      "                                      Count  Percentage\n",
      "h04_parto                                              \n",
      "Normal                                 2179   50.218944\n",
      "Cesariana de urg√™ncia (N√£o agendada)   1142   26.319428\n",
      "Cesariana agendada (eletiva)           1018   23.461627\n",
      "\n",
      "Distribution for j03_cor:\n",
      "                                                    Count  Percentage\n",
      "j03_cor                                                              \n",
      "Parda (mulata, cabocla, cafuza, mameluca ou mes...   2404   55.404471\n",
      "Branca                                               1335   30.767458\n",
      "Preta                                                 548   12.629638\n",
      "Amarela (origem japonesa, chinesa, coreana etc.)       35    0.806637\n",
      "Ind√≠gena                                               17    0.391795\n",
      "\n",
      "Distribution for k13_tempo_medida:\n",
      "                  Count  Percentage\n",
      "k13_tempo_medida                   \n",
      "Horas              3867   89.121917\n",
      "Dias                472   10.878083\n",
      "\n",
      "Distribution for k15_recebeu:\n",
      "                             Count  Percentage\n",
      "k15_recebeu                                   \n",
      "N√£o                           3358   77.391104\n",
      "Sim                            946   21.802259\n",
      "N√£o sabe/N√£o quis responder     35    0.806637\n",
      "\n",
      "Distribution for k16_liquido:\n",
      "                             Count  Percentage\n",
      "k16_liquido                                   \n",
      "N√£o                           3658   84.305139\n",
      "Sim                            650   14.980410\n",
      "N√£o sabe/N√£o quis responder     31    0.714450\n",
      "\n",
      "Distribution for k19_somente_medida:\n",
      "                    Count  Percentage\n",
      "k19_somente_medida                   \n",
      "Meses                3883   89.490666\n",
      "Dias                  456   10.509334\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# For each categorical column, show value counts and percentage\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\nDistribution for {column}:\")\n",
    "    value_counts = df[column].value_counts()\n",
    "    value_percentages = df[column].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Combine counts and percentages\n",
    "    summary = pd.DataFrame({\n",
    "        'Count': value_counts,\n",
    "        'Percentage': value_percentages\n",
    "    })\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142a915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSO DE CRIA√á√ÉO DO CLEANDATASET.CSV\n",
      "============================================================\n",
      "CRIANDO CLEANDATASET.CSV\n",
      "========================================\n",
      "üìä Dataset inicial: 4,339 pacientes\n",
      "\n",
      "üîç Procurando padr√µes de missing categ√≥rico:\n",
      "   k15_recebeu: 'N√£o sabe/N√£o quis responder': 35, 'N√£o sabe': 35, 'N√£o quis responder': 35\n",
      "   k16_liquido: 'N√£o sabe/N√£o quis responder': 31, 'N√£o sabe': 31, 'N√£o quis responder': 31\n",
      "\n",
      "‚úÇÔ∏è Removendo casos:\n",
      "   Total de casos √∫nicos a remover: 52\n",
      "   Casos removidos: 52\n",
      "   Casos restantes: 4,287\n",
      "\n",
      "üî¨ Verifica√ß√£o final:\n",
      "‚úÖ Confirmado: Nenhum missing categ√≥rico restante!\n",
      "\n",
      "üíæ Salvando CleanDataset.csv:\n",
      "üìÅ /Users/marcelosilva/Desktop/projectOne/3/D-Variable Analysis/CleanDataset.csv\n",
      "‚úÖ CleanDataset.csv salvo com sucesso!\n",
      "\n",
      "üìä CLEANDATASET.CSV - INFORMA√á√ïES:\n",
      "========================================\n",
      "üìà Linhas: 4,287\n",
      "üìà Colunas: 24\n",
      "üìà Tamanho do arquivo: 0.81 MB\n",
      "üìà Missing values num√©ricos: 0\n",
      "üìà Missing values categ√≥ricos: 0\n",
      "üìà Taxa de reten√ß√£o: 98.80%\n",
      "\n",
      "üèÜ QUALIDADE DO DATASET:\n",
      "‚úÖ DATASET COMPLETAMENTE LIMPO!\n",
      "   - 0 missing values num√©ricos\n",
      "   - 0 missing values categ√≥ricos\n",
      "   - 100% dados genu√≠nos\n",
      "\n",
      "üìã Distribui√ß√£o final das vari√°veis corrigidas:\n",
      "\n",
      "k15_recebeu:\n",
      "   N√£o: 3,352 (78.2%)\n",
      "   Sim: 935 (21.8%)\n",
      "\n",
      "k16_liquido:\n",
      "   N√£o: 3,640 (84.9%)\n",
      "   Sim: 647 (15.1%)\n",
      "\n",
      "üî¨ VALIDA√á√ÉO COMPLETA DO CLEANDATASET\n",
      "==================================================\n",
      "üìä Shape: (4287, 24)\n",
      "üìä Tipos de vari√°veis:\n",
      "   Num√©ricas: 16\n",
      "   Categ√≥ricas: 8\n",
      "üìä Missing values: 0\n",
      "\n",
      "üìã Resumo das vari√°veis categ√≥ricas:\n",
      "   b02_sexo: 2 categorias √∫nicas, mais frequente: 'Masculino'\n",
      "   d01_cor: 5 categorias √∫nicas, mais frequente: 'Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)'\n",
      "   h04_parto: 3 categorias √∫nicas, mais frequente: 'Normal'\n",
      "   j03_cor: 5 categorias √∫nicas, mais frequente: 'Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)'\n",
      "   k13_tempo_medida: 2 categorias √∫nicas, mais frequente: 'Horas'\n",
      "   k15_recebeu: 2 categorias √∫nicas, mais frequente: 'N√£o'\n",
      "   k16_liquido: 2 categorias √∫nicas, mais frequente: 'N√£o'\n",
      "   k19_somente_medida: 2 categorias √∫nicas, mais frequente: 'Meses'\n",
      "‚úÖ Nenhum padr√£o suspeito encontrado!\n",
      "\n",
      "üìä Estat√≠sticas b√°sicas das vari√°veis num√©ricas:\n",
      "   Vari√°veis num√©ricas: 16\n",
      "   Observa√ß√µes por vari√°vel: 4287 - 4287\n",
      "\n",
      "üéâ CLEANDATASET.CSV CRIADO COM SUCESSO!\n",
      "üìÇ Arquivo: CleanDataset.csv\n",
      "üìç Localiza√ß√£o: /Users/marcelosilva/Desktop/projectOne/3/D-Variable Analysis\n",
      "üìä Shape final: (4287, 24)\n",
      "üèÜ Qualidade: 100% dados limpos e completos!\n",
      "\n",
      "üìã AMOSTRA DO CLEANDATASET (5 primeiras linhas):\n",
      "============================================================\n",
      "       id_anon   b02_sexo                                            d01_cor  \\\n",
      "0  10951003402   Feminino                                             Branca   \n",
      "1  10951009402  Masculino  Parda (mulata, cabocla, cafuza, mameluca ou me...   \n",
      "2  10951023902   Feminino                                             Branca   \n",
      "3  11180012904  Masculino  Parda (mulata, cabocla, cafuza, mameluca ou me...   \n",
      "4  10215000103   Feminino  Parda (mulata, cabocla, cafuza, mameluca ou me...   \n",
      "\n",
      "                              h04_parto k15_recebeu k16_liquido  \n",
      "0                                Normal         N√£o         N√£o  \n",
      "1  Cesariana de urg√™ncia (N√£o agendada)         N√£o         N√£o  \n",
      "2  Cesariana de urg√™ncia (N√£o agendada)         Sim         N√£o  \n",
      "3  Cesariana de urg√™ncia (N√£o agendada)         Sim         Sim  \n",
      "4          Cesariana agendada (eletiva)         Sim         Sim  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_clean_dataset(df, output_path):\n",
    "    \"\"\"\n",
    "    Cria CleanDataset.csv removendo todos os casos com 'N√£o sabe/N√£o quis responder'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificar se o diret√≥rio existe, se n√£o, criar\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    print(\"CRIANDO CLEANDATASET.CSV\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Informa√ß√µes iniciais\n",
    "    initial_count = len(df)\n",
    "    print(f\"üìä Dataset inicial: {initial_count:,} pacientes\")\n",
    "    \n",
    "    # Fazer c√≥pia do dataset\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Identificar e contar casos com \"N√£o sabe/N√£o quis responder\"\n",
    "    patterns_to_remove = [\n",
    "        'N√£o sabe/N√£o quis responder',\n",
    "        'N√£o sabe',\n",
    "        'N√£o quis responder',\n",
    "        'NS/NR'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüîç Procurando padr√µes de missing categ√≥rico:\")\n",
    "    \n",
    "    total_cases_to_remove = set()  # Usar set para evitar duplicatas\n",
    "    removal_details = {}\n",
    "    \n",
    "    # Verificar cada coluna categ√≥rica\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        col_removals = 0\n",
    "        found_patterns = []\n",
    "        \n",
    "        for pattern in patterns_to_remove:\n",
    "            # Buscar padr√£o (case insensitive)\n",
    "            mask = df_clean[col].str.contains(pattern, case=False, na=False)\n",
    "            matching_cases = df_clean[mask].index.tolist()\n",
    "            \n",
    "            if len(matching_cases) > 0:\n",
    "                # Adicionar √≠ndices ao set de casos para remover\n",
    "                total_cases_to_remove.update(matching_cases)\n",
    "                col_removals += len(matching_cases)\n",
    "                found_patterns.append(f\"'{pattern}': {len(matching_cases)}\")\n",
    "        \n",
    "        if found_patterns:\n",
    "            removal_details[col] = {\n",
    "                'patterns': found_patterns,\n",
    "                'total_in_column': col_removals\n",
    "            }\n",
    "            print(f\"   {col}: {', '.join(found_patterns)}\")\n",
    "    \n",
    "    # Mostrar resumo dos casos a serem removidos\n",
    "    total_unique_removals = len(total_cases_to_remove)\n",
    "    \n",
    "    if total_unique_removals == 0:\n",
    "        print(\"‚úÖ Nenhum caso com missing categ√≥rico encontrado!\")\n",
    "        df_final = df_clean\n",
    "    else:\n",
    "        print(f\"\\n‚úÇÔ∏è Removendo casos:\")\n",
    "        print(f\"   Total de casos √∫nicos a remover: {total_unique_removals}\")\n",
    "        \n",
    "        # Remover casos identificados\n",
    "        df_final = df_clean.drop(index=list(total_cases_to_remove))\n",
    "        \n",
    "        print(f\"   Casos removidos: {initial_count - len(df_final)}\")\n",
    "        print(f\"   Casos restantes: {len(df_final):,}\")\n",
    "    \n",
    "    # Verifica√ß√£o final - confirmar que n√£o h√° mais missing categ√≥ricos\n",
    "    print(f\"\\nüî¨ Verifica√ß√£o final:\")\n",
    "    remaining_missing = 0\n",
    "    \n",
    "    for col in df_final.select_dtypes(include=['object']).columns:\n",
    "        for pattern in patterns_to_remove:\n",
    "            count = df_final[col].str.contains(pattern, case=False, na=False).sum()\n",
    "            remaining_missing += count\n",
    "    \n",
    "    if remaining_missing == 0:\n",
    "        print(\"‚úÖ Confirmado: Nenhum missing categ√≥rico restante!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Ainda existem {remaining_missing} missing categ√≥ricos!\")\n",
    "    \n",
    "    # Definir caminho do arquivo\n",
    "    filename = \"CleanDataset.csv\"\n",
    "    full_path = os.path.join(output_path, filename)\n",
    "    \n",
    "    # Salvar o dataset\n",
    "    print(f\"\\nüíæ Salvando CleanDataset.csv:\")\n",
    "    print(f\"üìÅ {full_path}\")\n",
    "    \n",
    "    try:\n",
    "        df_final.to_csv(full_path, index=False)\n",
    "        print(\"‚úÖ CleanDataset.csv salvo com sucesso!\")\n",
    "        \n",
    "        # Informa√ß√µes do arquivo\n",
    "        file_size = os.path.getsize(full_path) / (1024 * 1024)  # MB\n",
    "        \n",
    "        print(f\"\\nüìä CLEANDATASET.CSV - INFORMA√á√ïES:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"üìà Linhas: {len(df_final):,}\")\n",
    "        print(f\"üìà Colunas: {len(df_final.columns)}\")\n",
    "        print(f\"üìà Tamanho do arquivo: {file_size:.2f} MB\")\n",
    "        print(f\"üìà Missing values num√©ricos: {df_final.isnull().sum().sum()}\")\n",
    "        print(f\"üìà Missing values categ√≥ricos: {remaining_missing}\")\n",
    "        \n",
    "        # Taxa de reten√ß√£o\n",
    "        retention_rate = (len(df_final) / initial_count) * 100\n",
    "        print(f\"üìà Taxa de reten√ß√£o: {retention_rate:.2f}%\")\n",
    "        \n",
    "        # Resumo da qualidade dos dados\n",
    "        print(f\"\\nüèÜ QUALIDADE DO DATASET:\")\n",
    "        if df_final.isnull().sum().sum() == 0 and remaining_missing == 0:\n",
    "            print(\"‚úÖ DATASET COMPLETAMENTE LIMPO!\")\n",
    "            print(\"   - 0 missing values num√©ricos\")\n",
    "            print(\"   - 0 missing values categ√≥ricos\")\n",
    "            print(\"   - 100% dados genu√≠nos\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Dataset ainda tem alguns problemas\")\n",
    "        \n",
    "        # Mostrar distribui√ß√£o final das vari√°veis que tinham problemas\n",
    "        problem_vars = ['k15_recebeu', 'k16_liquido']\n",
    "        \n",
    "        print(f\"\\nüìã Distribui√ß√£o final das vari√°veis corrigidas:\")\n",
    "        for var in problem_vars:\n",
    "            if var in df_final.columns:\n",
    "                print(f\"\\n{var}:\")\n",
    "                value_counts = df_final[var].value_counts()\n",
    "                for value, count in value_counts.items():\n",
    "                    pct = (count / len(df_final)) * 100\n",
    "                    print(f\"   {value}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao salvar CleanDataset.csv: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def validate_clean_dataset(df_clean):\n",
    "    \"\"\"\n",
    "    Valida√ß√£o completa do CleanDataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî¨ VALIDA√á√ÉO COMPLETA DO CLEANDATASET\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Verificar shape\n",
    "    print(f\"üìä Shape: {df_clean.shape}\")\n",
    "    \n",
    "    # 2. Verificar tipos de dados\n",
    "    print(f\"üìä Tipos de vari√°veis:\")\n",
    "    print(f\"   Num√©ricas: {len(df_clean.select_dtypes(include=[np.number]).columns)}\")\n",
    "    print(f\"   Categ√≥ricas: {len(df_clean.select_dtypes(include=['object']).columns)}\")\n",
    "    \n",
    "    # 3. Verificar missing values\n",
    "    total_missing = df_clean.isnull().sum().sum()\n",
    "    print(f\"üìä Missing values: {total_missing}\")\n",
    "    \n",
    "    # 4. Verificar valores √∫nicos das vari√°veis categ√≥ricas\n",
    "    print(f\"\\nüìã Resumo das vari√°veis categ√≥ricas:\")\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        unique_count = df_clean[col].nunique()\n",
    "        most_frequent = df_clean[col].mode().iloc[0] if len(df_clean[col].mode()) > 0 else \"N/A\"\n",
    "        print(f\"   {col}: {unique_count} categorias √∫nicas, mais frequente: '{most_frequent}'\")\n",
    "    \n",
    "    # 5. Verificar se h√° padr√µes suspeitos restantes\n",
    "    suspicious_patterns = ['999', '99', 'N√£o sabe', 'NS', 'NR', 'Missing']\n",
    "    \n",
    "    found_suspicious = False\n",
    "    for col in categorical_cols:\n",
    "        for pattern in suspicious_patterns:\n",
    "            if df_clean[col].astype(str).str.contains(pattern, case=False, na=False).any():\n",
    "                print(f\"‚ö†Ô∏è Padr√£o suspeito '{pattern}' encontrado em {col}\")\n",
    "                found_suspicious = True\n",
    "    \n",
    "    if not found_suspicious:\n",
    "        print(f\"‚úÖ Nenhum padr√£o suspeito encontrado!\")\n",
    "    \n",
    "    # 6. Estat√≠sticas b√°sicas\n",
    "    print(f\"\\nüìä Estat√≠sticas b√°sicas das vari√°veis num√©ricas:\")\n",
    "    numeric_summary = df_clean.describe()\n",
    "    print(f\"   Vari√°veis num√©ricas: {len(numeric_summary.columns)}\")\n",
    "    print(f\"   Observa√ß√µes por vari√°vel: {numeric_summary.loc['count'].min():.0f} - {numeric_summary.loc['count'].max():.0f}\")\n",
    "    \n",
    "    return total_missing == 0 and not found_suspicious\n",
    "\n",
    "# EXECUTAR CRIA√á√ÉO DO CLEANDATASET\n",
    "# =================================\n",
    "\n",
    "output_directory = \"/Users/marcelosilva/Desktop/projectOne/3/D-Variable Analysis\"\n",
    "\n",
    "print(\"PROCESSO DE CRIA√á√ÉO DO CLEANDATASET.CSV\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criar CleanDataset.csv\n",
    "clean_dataset = create_clean_dataset(df, output_directory)\n",
    "\n",
    "# Validar dataset criado\n",
    "if clean_dataset is not None:\n",
    "    is_valid = validate_clean_dataset(clean_dataset)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"\\nüéâ CLEANDATASET.CSV CRIADO COM SUCESSO!\")\n",
    "        print(f\"üìÇ Arquivo: CleanDataset.csv\")\n",
    "        print(f\"üìç Localiza√ß√£o: {output_directory}\")\n",
    "        print(f\"üìä Shape final: {clean_dataset.shape}\")\n",
    "        print(f\"üèÜ Qualidade: 100% dados limpos e completos!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è CleanDataset criado mas precisa de revis√£o!\")\n",
    "    \n",
    "    # Mostrar amostra do dataset final\n",
    "    print(f\"\\nüìã AMOSTRA DO CLEANDATASET (5 primeiras linhas):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Mostrar algumas colunas representativas\n",
    "    sample_cols = ['id_anon', 'b02_sexo', 'd01_cor', 'h04_parto', 'k15_recebeu', 'k16_liquido']\n",
    "    available_cols = [col for col in sample_cols if col in clean_dataset.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        print(clean_dataset[available_cols].head())\n",
    "else:\n",
    "    print(\"‚ùå Falha na cria√ß√£o do CleanDataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
